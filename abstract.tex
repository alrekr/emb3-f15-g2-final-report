This report describes the development of a UAS that allows a UAV to take off, fly a preprogrammed route if conditions allow flying, return to the base by GPS and then be guided via computer vision to land and recharge on a ground base. This system is not fully developed but the steps towards is described in this report. 

A physical landing platform was developed. Two designs were in consideration and an analysis of the two is made. The landing platform shaped as a cone was chosen as the best solution. Test were made to ensure that the UAV would slide correctly into place. A real prototype of the platform were made. Connector pods were designed, tested and redesigned. The prototype was equipped with LEDs to show connections to the pods. The physical platforms works well, but is just a prototype and materials and design needs to be refined. 

The computer vision guiding was designed using the ROS framework. This was found to make testing of multiple tracking methods and testing with recorded video easier. Three different tracking methods for location the UAV in the image were tested.  Only one of these were performing useful in a outdoor environment, due to difficult light conditions. A method for calculating the position of the UAV 3D position relative to the camera, in SI units, was also developed. The 3D position made it possible to visualize the drone in the RobWorkStudio 3D simulator. The tracking is still just a prototype but ended up being a nice proof of concept. 

The firmware for a IRIS drone with Pixhawk was examined. Both APM and Pixhawk flight stack were used to do test flights. They were found equally good, when calibration was done correctly. Different flight modes for Pixhawk was examined and auto, AltHold and land was found best suited for making use in automatic landing. A script for using METAR and TAF messages for automatic weather forecasts was found. The use of MAVRos for controlling the UAV was examined and the RCOverride method was found useful. Pseudocode for an automatic landing system was shown.

The whole system was not tested together as the subtasks was not finished. Future work should is to finish the subtasks and build them together into one system. 